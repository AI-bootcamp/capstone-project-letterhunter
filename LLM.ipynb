{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install deep-translator"
      ],
      "metadata": {
        "id": "Ay8H4eUYQewW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "jy2U9zQvO9D5",
        "outputId": "83e32849-1dd0-45e9-aa17-549a9c2bb26d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deep_translator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5e9f0ed8c405>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_translator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleTranslator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load SaudiBERT model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deep_translator'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Load SaudiBERT model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"faisalq/SaudiBERT\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"faisalq/SaudiBERT\")\n",
        "\n",
        "def translate_to_arabic(word):\n",
        "    \"\"\"\n",
        "    Translate an English word to Arabic using Google Translator.\n",
        "    :param word: str, The English word to translate.\n",
        "    :return: str, Translated Arabic word.\n",
        "    \"\"\"\n",
        "    translator = GoogleTranslator(source='en', target='ar')\n",
        "    return translator.translate(word)\n",
        "\n",
        "def get_synonyms(word):\n",
        "    \"\"\"\n",
        "    Retrieve synonyms for a given Arabic word using SaudiBERT.\n",
        "    :param word: str, The Arabic word to find synonyms for.\n",
        "    :return: list, Top synonyms generated by the model.\n",
        "    \"\"\"\n",
        "    # Use the word with a mask token in a meaningful Arabic context\n",
        "    masked_sentence = f\"كلمة {tokenizer.mask_token} تعني {word}.\"\n",
        "\n",
        "    # Tokenize the input\n",
        "    inputs = tokenizer(masked_sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Predict masked tokens\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Find the index of the masked token\n",
        "    mask_token_index = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "\n",
        "    # Get the top predictions for the masked token\n",
        "    mask_token_logits = logits[0, mask_token_index, :]\n",
        "    top_k_indices = torch.topk(mask_token_logits, k=10, dim=1).indices[0].tolist()\n",
        "\n",
        "    # Decode the predictions into words\n",
        "    synonyms = tokenizer.convert_ids_to_tokens(top_k_indices)\n",
        "\n",
        "    return synonyms\n",
        "\n",
        "# Example usage\n",
        "english_word = \"phone\"  # Example English word\n",
        "translated_word = translate_to_arabic(english_word)\n",
        "synonyms = get_synonyms(translated_word)\n",
        "\n",
        "print(f\"English Word: {english_word}\")\n",
        "print(f\"Arabic Translation: {translated_word}\")\n",
        "print(f\"Synonyms: {synonyms}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "english_word = \"water\"  # Example English word\n",
        "translated_word = translate_to_arabic(english_word)\n",
        "synonyms = get_synonyms(translated_word)\n",
        "\n",
        "print(f\"English Word: {english_word}\")\n",
        "print(f\"Arabic Translation: {translated_word}\")\n",
        "print(f\"Synonyms: {synonyms}\")"
      ],
      "metadata": {
        "id": "4i7dIhmYmIbg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}